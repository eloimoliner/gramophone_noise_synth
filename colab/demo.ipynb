{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eloimoliner/gramophone_noise_synth/blob/main/colab/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Realistic Gramophone Noise Synthesis using a Diffusion Model"
      ],
      "metadata": {
        "id": "jbe_aWYkjWRH"
      },
      "id": "jbe_aWYkjWRH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is a demo of the historical music denoising method proposed in:\n",
        "\n",
        "> E. Moliner and V. Välimäki,, \"A two-stage U-Net for high-fidelity denosing of historical recordings\", submitted to IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Singapore, May, 2022\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://user-images.githubusercontent.com/64018465/131505025-e4530f55-fe5d-4bf4-ae64-cc9a502e5874.png\" alt=\"Schema represention\"\n",
        "width=\"400px\"></p>\n",
        "\n",
        "Listen to our [audio samples](http://research.spa.aalto.fi/publications/papers/icassp22-denoising/)\n",
        "\n",
        "You can freely use it to denoise your own historical recordings.\n",
        "\n",
        "### Instructions for running:\n",
        "\n",
        "* Make sure to use a GPU runtime, click:  __Runtime >> Change Runtime Type >> GPU__\n",
        "* Press ▶️ on the left of each of the cells\n",
        "* View the code: Double-click any of the cells\n",
        "* Hide the code: Double click the right side of the cell\n"
      ],
      "metadata": {
        "id": "8UON6ncSApA9"
      },
      "id": "8UON6ncSApA9"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Setup environment\n",
        "\n",
        "#@markdown Execute this cell to download the code and weights \n",
        "! git clone https://github.com/eloimoliner/gramophone_noise_synth.git\n",
        "%cd gramophone_noise_synth\n",
        "! wget https://github.com/eloimoliner/gramophone_noise_synth/releases/download/gramophonediff/weights-750000.pt\n",
        "! mkdir experiments\n",
        "! mkdir experiments/trained_model\n",
        "! mv weights-750000.pt experiments/trained_model/\n",
        "\n",
        "!pip install omegaconf\n"
      ],
      "metadata": {
        "id": "LskA4-zOpxCZ",
        "cellView": "form"
      },
      "id": "LskA4-zOpxCZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Imports and others\n",
        "\n",
        "#@markdown\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchaudio\n",
        "import yaml\n",
        "import os\n",
        "from pathlib import Path\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import math\n",
        "from scipy.fft import fft, ifft\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "from omegaconf.omegaconf import open_dict\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "#from learner import Learner\n",
        "from model import UNet\n",
        "\n",
        "from getters import get_sde\n",
        "\n",
        "\n",
        "import soundfile as sf\n",
        "#from sashimi.sashimi import Sashimi\n",
        "\n",
        "from inference import GramophoneSampler \n",
        "\n",
        "from guide_synthesis import noise_presynthesis\n",
        "\n",
        "args = yaml.safe_load(Path('conf/conf.yaml').read_text())\n",
        "class dotdict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "args=dotdict(args)\n",
        "args.unet=dotdict(args.unet)\n",
        "\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "dirname = os.getcwd()\n",
        "model_dir=\"experiments/trained_model/weights-750000.pt\"\n",
        "\n",
        "\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if args.architecture==\"unet\":\n",
        "    model = UNet(args).to(device)\n",
        "\n",
        "\n",
        "\n",
        "state_dict= torch.load(model_dir, map_location=device)\n",
        "\n",
        "if hasattr(model, 'module') and isinstance(model.module, nn.Module):\n",
        "    model.module.load_state_dict(state_dict['model'])\n",
        "else:\n",
        "    model.load_state_dict(state_dict['model'])\n",
        "\n",
        "torch.backends.cudnn.benchmark = True #I dont know if this is useful\n",
        "\n",
        "\n",
        "sde = get_sde(args.sde_type, args.sde_kwargs)\n",
        "\n",
        "\n",
        "def plot_spec(x,ax, refr=None):\n",
        "    D = librosa.stft(x, hop_length=128, n_fft=2048)\n",
        "    if refr==None:\n",
        "      refr=np.max(np.abs(D))\n",
        "    S_db = 10*np.log10(np.abs(D)/refr)\n",
        "    #D = librosa.amplitude_to_db(np.abs(librosa.stft(x, n_fft=1024,hop_length=128)))\n",
        "    #librosa.display.specshow(D,ax=ax)\n",
        "    librosa.display.specshow(S_db, cmap=\"inferno\",vmax=0,vmin=-50,x_axis='time', y_axis='log', sr=44100,hop_length=128, ax=ax)\n",
        "    return refr\n"
      ],
      "metadata": {
        "id": "jzcKMXGTrDaJ"
      },
      "id": "jzcKMXGTrDaJ",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Unconditional Sampling"
      ],
      "metadata": {
        "id": "DG5S5MB-wCpj"
      },
      "id": "DG5S5MB-wCpj"
    },
    {
      "cell_type": "code",
      "source": [
        "sampler=GramophoneSampler(model,sde)\n",
        "steps=100\n",
        "t_period=1/3\n",
        "\n",
        "noise = sampler.predict_unconditional(steps,5, t_period)\n",
        "\n"
      ],
      "metadata": {
        "id": "HdcCCuKiv2vG",
        "outputId": "a993efe0-13ee-40f5-f056-810199f8cf6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "id": "HdcCCuKiv2vG",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "period split at step  33\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-26226a69d656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_unconditional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_period\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gramophone_noise_synth/inference.py\u001b[0m in \u001b[0;36mpredict_unconditional\u001b[0;34m(self, nb_steps, num_periods, taup, periods_separated)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m#sample from prior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generating period 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Download\n",
        "\n",
        "#@markdown Execute this cell to download the denoised recording\n",
        "files.download(wav_output_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3tEshWBezYvf",
        "outputId": "54588c26-0b3c-42bf-aca2-8316ab54603f"
      },
      "id": "3tEshWBezYvf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3e3ca242-937f-408e-a16c-4aa5bb2b9e50\", \"Carmen-Habanera_(Love_is_Like_a_Woo_-_Marguerite_D'Alvarez_noisy_input_denoised.wav\", 17961334)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "v_FuSJ4J-WO-"
      },
      "id": "v_FuSJ4J-WO-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}